loss_config:
  losses:
    - CrossEntropy:
        weight:
          - 0.5
          - 0.5
        reduction: mean
    - DiceLoss:
  weights:
    - 0.5
    - 0.5

optimizer:
  name: Adam
  params:
    lr: 0.0001
    betas:
      - 0.9
      - 0.999

model:
  name: UnetPlusPlus
  downsample_target: false
  load_args:
    pre_trained_name: imagenet
    encoder_name: resnet34

data_config:
  path_to_dataset: ./dataset/Kvasir-SEG/
  train_test_split:
    lens:
      - 850
      - 150
    seed: 42
  augment_config:
    train: ./augmentation_config_train.yaml
    test: ./augmentation_config_test.yaml

trainer_args:
  output_dir: expirements/unet_plus_plus_baseline
  overwrite_output_dir: true
  evaluation_strategy: steps
  eval_steps: 20
  learning_rate: 0.0001
  lr_scheduler_type: linear
  logging_strategy: steps
  logging_first_step: true
  logging_steps: 20
  save_strategy: steps
  save_steps: 20
  seed: 42
  data_seed: 42
  metric_for_best_model: dice
  greater_is_better: true
  save_total_limit: 2
  ignore_data_skip: false
  max_steps: 1000
  report_to: wandb
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 8
  label_names:
    - target

wandb_init:
  project: kvasir_seg
  name: unet_plus_plus_baseline

compute_metrics:
  thresholds:
    -
      - 0.
      - 0.1
    -
      - 0.1
      - 0.2
    -
      - 0.2
      - 0.3
    -
      - 0.3
      - 0.5
    -
      - 0.5
      - 1.0
